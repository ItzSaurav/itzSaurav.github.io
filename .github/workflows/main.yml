name: Fetch Daily AI News (Free)

on:
  schedule:
    # Runs daily at 00:00 UTC (midnight). Adjust as needed.
    - cron: '0 0 * * *'
  workflow_dispatch: # Allows manual triggering from GitHub Actions tab

jobs:
  update-news:
    runs-on: ubuntu-latest
    permissions:
      contents: write # Make sure this is still here!
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install Python dependencies
        run: |
          pip install requests # <--- Only 'requests' is needed now for API calls
          # Remove or comment out 'beautifulsoup4' and 'lxml' if they were there
          # pip install beautifulsoup4 lxml

      - name: Run scraper and generate news.json
        env:
          # THIS IS THE CRUCIAL LINE: Passes the secret to your script
          GNEWS_API_KEY: ${{ secrets.GNEWS_API_KEY }}
        run: python scraper.py

      - name: Commit and push changes
        # This step will only commit if news.json has actually changed
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add news.json
          git diff --staged --quiet || git commit -m "ðŸ¤– Daily AI News Update: $(date +%Y-%m-%d)"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
